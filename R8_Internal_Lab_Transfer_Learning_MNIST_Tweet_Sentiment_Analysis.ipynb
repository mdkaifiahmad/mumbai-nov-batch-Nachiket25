{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFfDTfhlaEI_"
   },
   "source": [
    "# Transfer Learning MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNwbqCFRaEJC"
   },
   "source": [
    "* Train a simple convnet on the MNIST dataset the first 5 digits [0..4].\n",
    "* Freeze convolutional layers and fine-tune dense layers for the classification of digits [5..9]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YUB1uDW_8XIy"
   },
   "source": [
    "## 1. Import necessary libraries for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rsj4t5HTaEJE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing important modules\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten,Activation, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IXrn3heBaEJa"
   },
   "source": [
    "## 2. Import MNIST data and create 2 datasets with one dataset having digits from 0 to 4 and other from 5 to 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjDuiK6ztgOK"
   },
   "outputs": [],
   "source": [
    "(X_1, y_1), (X_2, y_2) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXIR8kG8dBYt"
   },
   "outputs": [],
   "source": [
    "X_0_4=X_1[y_1<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZTz3AwJd7CN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2532b79a9e8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_0_4[140], cmap=plt.get_cmap('gray')) #checking the data is between 0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1560684860273,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "9RTrekU8eduf",
    "outputId": "b176ef8d-6118-4405-b299-8eff1c9578ac"
   },
   "outputs": [],
   "source": [
    "y_0_4=y_1[y_1<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vXk9MrweMxF"
   },
   "outputs": [],
   "source": [
    "X_4_9=X_2[y_2>4]\n",
    "y_4_9=y_2[y_2>4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gv-531waeVSc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2532bbe94e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_4_9[10], cmap=plt.get_cmap('gray')) #checking the data is between 4-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 966,
     "status": "ok",
     "timestamp": 1560684864049,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "nUEEVABaezRe",
    "outputId": "437308ac-6c07-4a13-dec8-0d8199b6bdac"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9qU14lYL9A5g"
   },
   "source": [
    "## 3. Print x_train, y_train, x_test and y_test for both the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1560684976956,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "Z9OrszhJ0SgJ",
    "outputId": "74f3ce0f-4b2f-4874-85e9-7765436045f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30596, 28, 28)\n",
      "(30596,)\n"
     ]
    }
   ],
   "source": [
    "print (X_0_4.shape)\n",
    "print(y_0_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1560684979780,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "sJswV4xk9jQS",
    "outputId": "43544b82-ccc9-423d-8b6e-c556a0711730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4861, 28, 28)\n",
      "(4861,)\n"
     ]
    }
   ],
   "source": [
    "print (X_4_9.shape)\n",
    "print(y_4_9.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cB9BPFzr9oDF"
   },
   "source": [
    "## ** 4. Let us take only the dataset (x_train, y_train, x_test, y_test) for Integers 0 to 4 in MNIST **\n",
    "## Reshape x_train and x_test to a 4 Dimensional array (channel = 1) to pass it into a Conv2D layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlQRPfFzaEJx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24476, 28, 28)\n",
      "(6120, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_0_4, y_0_4, test_size=0.2, random_state=2)\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(24476,28,28,1)\n",
    "X_test=X_test.reshape(6120,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jLQr-b3F-hw8"
   },
   "source": [
    "## 5. Normalize x_train and x_test by dividing it by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlEZIAG5-g2I"
   },
   "outputs": [],
   "source": [
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, 2], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pytVBaw4-vMi"
   },
   "source": [
    "## 6. Use One-hot encoding to divide y_train and y_test into required no of output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "co7EaCmssecV"
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V48xiua4-uUi"
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6120, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "elPkI44g_C2b"
   },
   "source": [
    "## 7. Build a sequential model with 2 Convolutional layers with 32 kernels of size (3,3) followed by a Max pooling layer of size (2,2) followed by a drop out layer to be trained for classification of digits 0-4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPD2FqCosHNY"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MU09mm9F89gO"
   },
   "outputs": [],
   "source": [
    "    # Define Model\n",
    "    model = Sequential()\n",
    "\n",
    "    #Add a Convolutional Layer with 32 filters of size 3X3 and activation function as 'ReLU' \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1),name='conv_1'))\n",
    "\n",
    "    #Add a Convolutional Layer with 64 filters of size 3X3 and activation function as 'ReLU' \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',name='conv_2'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    # Dropout\n",
    "    model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJQaycRO_3Au"
   },
   "source": [
    "## 8. Post that flatten the data and add 2 Dense layers with 128 neurons and neurons = output classes with activation = 'relu' and 'softmax' respectively. Add dropout layer inbetween if necessary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 97080,
     "status": "ok",
     "timestamp": 1560685105549,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "vOZeRbK7t9AT",
    "outputId": "a3143496-8348-44be-87a6-06018b7b761c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30596 samples, validate on 5139 samples\n",
      "Epoch 1/10\n",
      "30596/30596 [==============================] - 10s 325us/step - loss: 0.0885 - acc: 0.9733 - val_loss: 0.0099 - val_acc: 0.9961\n",
      "Epoch 2/10\n",
      "30596/30596 [==============================] - 10s 314us/step - loss: 0.0289 - acc: 0.9906 - val_loss: 0.0087 - val_acc: 0.9971\n",
      "Epoch 3/10\n",
      "30596/30596 [==============================] - 10s 311us/step - loss: 0.0199 - acc: 0.9937 - val_loss: 0.0106 - val_acc: 0.9957\n",
      "Epoch 4/10\n",
      "30596/30596 [==============================] - 9s 310us/step - loss: 0.0155 - acc: 0.9952 - val_loss: 0.0074 - val_acc: 0.9973\n",
      "Epoch 5/10\n",
      "30596/30596 [==============================] - 9s 310us/step - loss: 0.0124 - acc: 0.9958 - val_loss: 0.0098 - val_acc: 0.9975\n",
      "Epoch 6/10\n",
      "30596/30596 [==============================] - 10s 311us/step - loss: 0.0137 - acc: 0.9956 - val_loss: 0.0049 - val_acc: 0.9984\n",
      "Epoch 7/10\n",
      "30596/30596 [==============================] - 10s 311us/step - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0077 - val_acc: 0.9963\n",
      "Epoch 8/10\n",
      "30596/30596 [==============================] - 10s 311us/step - loss: 0.0097 - acc: 0.9969 - val_loss: 0.0051 - val_acc: 0.9984\n",
      "Epoch 9/10\n",
      "30596/30596 [==============================] - 10s 313us/step - loss: 0.0074 - acc: 0.9975 - val_loss: 0.0048 - val_acc: 0.9979\n",
      "Epoch 10/10\n",
      "30596/30596 [==============================] - 10s 312us/step - loss: 0.0089 - acc: 0.9970 - val_loss: 0.0057 - val_acc: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7fb860bd30>"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Fully Connected Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # More Dropout\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Prediction Layer\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "     # Loss and Optimizer\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Store Training Results\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=7, verbose=1, mode='auto')\n",
    "    callback_list = [early_stopping]\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x_train_1, y_train1_cat, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
    "              validation_data=(x_test_1, y_test1_cat), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "my1P09bxAv8H"
   },
   "source": [
    "## 9. Print the training and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3701,
     "status": "ok",
     "timestamp": 1560685119304,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "kgqwE7RklLPr",
    "outputId": "e0c923cb-b228-4d26-abc1-261240856b7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30596/30596 [==============================] - 3s 88us/step\n",
      "Train Accuracy : 99.96731598901818 %\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = model.evaluate(x_train, y_train)\n",
    "print(\"Train Accuracy :\",train_accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1242,
     "status": "ok",
     "timestamp": 1560685121697,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "yf7F8Gdutbf0",
    "outputId": "ad3b5c9f-8833-4950-bd00-de04eb2e8c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5139/5139 [==============================] - 1s 99us/step\n",
      "Test Accuracy : 99.80540961276513 %\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Accuracy :\",test_accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z78o3WIjaEJ3"
   },
   "source": [
    "## 10. Make only the dense layers to be trainable and convolutional layers to be non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1560685127198,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "brN7VZHFaEJ4",
    "outputId": "09c8f27f-33bb-4475-c3c0-250ec5484153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mconv_1\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mconv_2\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mmax_pooling2d_4\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdropout_6\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mflatten_3\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdense_5\u001b[0m\n",
      "\u001b[31mTrue\u001b[0m\n",
      "\u001b[34mactivation_7\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdropout_7\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdense_6\u001b[0m\n",
      "\u001b[31mTrue\u001b[0m\n",
      "\u001b[34mactivation_8\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Freezing layers in the model which don't have 'dense' in their name\n",
    "for layer in model.layers:\n",
    "  if('dense' not in layer.name): #prefix detection to freeze layers which does not have dense\n",
    "    #Freezing a layer\n",
    "    layer.trainable = False\n",
    "    \n",
    "#Module to print colourful statements\n",
    "from termcolor import colored\n",
    "\n",
    "#Check which layers have been frozen \n",
    "for layer in model.layers:\n",
    "  print (colored(layer.name, 'blue'))\n",
    "  print (colored(layer.trainable, 'red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4opnW7o0BJ8P"
   },
   "source": [
    "## 11. Use the model trained on 0 to 4 digit classification and train it on the dataset which has digits 5 to 9  (Using Transfer learning keeping only the dense layers to be trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2DHgPt8qXnI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3888, 28, 28)\n",
      "(973, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_4_9, y_4_9, test_size=0.2, random_state=2)\n",
    "print (X_train2.shape)\n",
    "print (X_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "futUmim7qcHR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NHZQINYXw2gb"
   },
   "outputs": [],
   "source": [
    "X_train2=X_train2.reshape(3888,28,28,1)\n",
    "X_test2=X_test2.reshape(973,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2 /= 255\n",
    "x_test_2 /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_FHEU1RFfZb"
   },
   "outputs": [],
   "source": [
    "y_train2 = keras.utils.to_categorical(y_train2)\n",
    "y_test2= keras.utils.to_categorical(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "naNSFuBmGdHa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test2[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2=y_train2[:,5:]\n",
    "y_test2=y_test2[:,5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8PcfeVjgHe47"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "#To use adam optimizer for learning weights with learning rate = 0.001\n",
    "optimizer = Adam(lr=0.001)\n",
    "#Set the loss function and optimizer for the model training\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 64388,
     "status": "ok",
     "timestamp": 1560685776800,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "lCFcYHTm6-cE",
    "outputId": "8bf45635-75b1-459e-9e04-3845c5f59eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29404 samples, validate on 4861 samples\n",
      "Epoch 1/10\n",
      "29404/29404 [==============================] - 7s 226us/step - loss: 0.0134 - acc: 0.9956 - val_loss: 0.0248 - val_acc: 0.9949\n",
      "Epoch 2/10\n",
      "29404/29404 [==============================] - 6s 213us/step - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0232 - val_acc: 0.9949\n",
      "Epoch 3/10\n",
      "29404/29404 [==============================] - 6s 214us/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0226 - val_acc: 0.9953\n",
      "Epoch 4/10\n",
      "29404/29404 [==============================] - 6s 213us/step - loss: 0.0081 - acc: 0.9970 - val_loss: 0.0263 - val_acc: 0.9947\n",
      "Epoch 5/10\n",
      "29404/29404 [==============================] - 6s 212us/step - loss: 0.0087 - acc: 0.9967 - val_loss: 0.0218 - val_acc: 0.9953\n",
      "Epoch 6/10\n",
      "29404/29404 [==============================] - 6s 213us/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.0221 - val_acc: 0.9949\n",
      "Epoch 7/10\n",
      "29404/29404 [==============================] - 6s 214us/step - loss: 0.0066 - acc: 0.9977 - val_loss: 0.0222 - val_acc: 0.9957\n",
      "Epoch 8/10\n",
      "29404/29404 [==============================] - 6s 215us/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.0268 - val_acc: 0.9947\n",
      "Epoch 9/10\n",
      "29404/29404 [==============================] - 6s 213us/step - loss: 0.0072 - acc: 0.9974 - val_loss: 0.0236 - val_acc: 0.9957\n",
      "Epoch 10/10\n",
      "29404/29404 [==============================] - 6s 213us/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0244 - val_acc: 0.9955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7fb93b88d0>"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training on the dataset\n",
    "model.fit(x_train2, y_train2,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test2, y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoDozqghCJZ4"
   },
   "source": [
    "## 12. Print the accuracy for classification of digits 5 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3390,
     "status": "ok",
     "timestamp": 1560685836644,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "LRWizZIpCUKg",
    "outputId": "cac2cf51-de5d-4a5b-ca20-4c59b4484a4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29404/29404 [==============================] - 3s 91us/step\n",
      "Train loss: 0.0003386955433130696\n",
      "Train accuracy: 99.99319820432594 %\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model on train set\n",
    "score = model.evaluate(x_train2, y_train2)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1]*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1274,
     "status": "ok",
     "timestamp": 1560685857168,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "9fCxgb5s49Cj",
    "outputId": "88188538-c61f-4e29-98c5-ef1102f34bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4861/4861 [==============================] - 0s 95us/step\n",
      "Test loss: 0.024438329167176503\n",
      "Test accuracy: 99.54741822670232 %\n"
     ]
    }
   ],
   "source": [
    "#Testing the model on test set\n",
    "score = model.evaluate(x_test2, y_test2)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FU-HwvIdH0M-"
   },
   "source": [
    "## Sentiment analysis <br> \n",
    "\n",
    "The objective of the second problem is to perform Sentiment analysis from the tweets data collected from the users targeted at various mobile devices.\n",
    "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAQDiZHRH0M_"
   },
   "source": [
    "### 13. Read the dataset (tweets.csv) and drop the NA's while reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1560686050138,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "i0ar_FW733_f",
    "outputId": "bb8c2e02-0a4a-4e87-8069-eaa9e95220fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3eXGIe-SH0NA"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/drive/My Drive/Colab Notebooks/data/tweets.csv', engine='python').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 922,
     "status": "ok",
     "timestamp": 1560688729672,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "CWeWe1eJH0NF",
    "outputId": "fa5dc6b6-2b1a-4d4e-b723-474b6c06376e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...                                   Negative emotion\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...                                   Positive emotion\n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...  ...                                   Positive emotion\n",
       "3  @sxsw I hope this year's festival isn't as cra...  ...                                   Negative emotion\n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...                                   Positive emotion\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPJvTjefH0NI"
   },
   "source": [
    "### 14. Preprocess the text and add the preprocessed text in a column with name `text` in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Me_JjUVyKqiR"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5iec5s9gH0NI"
   },
   "outputs": [],
   "source": [
    "#preprocessing using special character removal\n",
    "def preprocess(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQSmqA-vH0NT"
   },
   "outputs": [],
   "source": [
    "data['text'] = [preprocess(text) for text in data.tweet_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1333,
     "status": "ok",
     "timestamp": 1560688737498,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "7kX-WoJDH0NV",
    "outputId": "7ae5d826-d2e7-4510-96b2-c21ff51cb486"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley83 I have a 3G iPhone After 3 hrs tweeti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee Know about fludapp  Awesome iPadiPhon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin Can not wait for iPad 2 also They s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>sxsw I hope this years festival isnt as crashy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff on Fri SXSW Marissa Maye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  ...                                               text\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...  wesley83 I have a 3G iPhone After 3 hrs tweeti...\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...  jessedee Know about fludapp  Awesome iPadiPhon...\n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...  ...  swonderlin Can not wait for iPad 2 also They s...\n",
       "3  @sxsw I hope this year's festival isn't as cra...  ...  sxsw I hope this years festival isnt as crashy...\n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...  sxtxstate great stuff on Fri SXSW Marissa Maye...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGWB3P2WH0NY"
   },
   "source": [
    "### 15. Consider only rows having Positive emotion and Negative emotion and remove other rows from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdgA_8N2H0NY"
   },
   "outputs": [],
   "source": [
    "emotion = ['Negative emotion','Positive emotion']\n",
    "data_filtered = data[data.is_there_an_emotion_directed_at_a_brand_or_product.isin(emotion)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 726,
     "status": "ok",
     "timestamp": 1560688741938,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "_Jlu-reIH0Na",
    "outputId": "332ebfc8-9bd0-4fa0-dc5c-789b34637f35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive emotion    2672\n",
       "Negative emotion     519\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.is_there_an_emotion_directed_at_a_brand_or_product.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1203,
     "status": "ok",
     "timestamp": 1560688745815,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "s56IMrUYQCN_",
    "outputId": "66f7d7fa-4f1b-4587-dd2d-02fc9c4c868a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3191, 4)"
      ]
     },
     "execution_count": 215,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SotCRvkDH0Nf"
   },
   "source": [
    "### 16. Represent text as numerical data using `CountVectorizer` and get the document term frequency matrix\n",
    "\n",
    "#### Use `vect` as the variable name for initialising CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YcbkY4sgH0Ng"
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 812,
     "status": "ok",
     "timestamp": 1560688750607,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "KyXtZGr-H0Nl",
    "outputId": "60aab1a0-4553-4a89-c365-d19bb7177fd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 217,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the 'vocabulary' of the training data\n",
    "vect.fit(data_filtered['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1406,
     "status": "ok",
     "timestamp": 1560688754279,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "aIdZYxJtH0Nq",
    "outputId": "91c632c0-b28e-44bb-bb58-42a72600a772"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3191x6103 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 52449 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 218,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform data into a 'document-term matrix'\n",
    "data_filtered_dtm = vect.transform(data_filtered['text'])\n",
    "data_filtered_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1369,
     "status": "ok",
     "timestamp": 1560688756341,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "puYWTRxPN20p",
    "outputId": "671c61d4-ca7d-4f83-c358-d4ef503824e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>0310</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>100s</th>\n",
       "      <th>100tc</th>\n",
       "      <th>101</th>\n",
       "      <th>1030</th>\n",
       "      <th>1045am3</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>10am</th>\n",
       "      <th>10k</th>\n",
       "      <th>10mins</th>\n",
       "      <th>10pm</th>\n",
       "      <th>10x</th>\n",
       "      <th>11</th>\n",
       "      <th>11m</th>\n",
       "      <th>11ntc</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>1230p</th>\n",
       "      <th>12b</th>\n",
       "      <th>12th</th>\n",
       "      <th>13</th>\n",
       "      <th>130000</th>\n",
       "      <th>136</th>\n",
       "      <th>14</th>\n",
       "      <th>140608</th>\n",
       "      <th>1413</th>\n",
       "      <th>1415</th>\n",
       "      <th>14day</th>\n",
       "      <th>15</th>\n",
       "      <th>150</th>\n",
       "      <th>1500</th>\n",
       "      <th>150m</th>\n",
       "      <th>157</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>you_</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>youneedthis</th>\n",
       "      <th>youquot</th>\n",
       "      <th>your</th>\n",
       "      <th>youre</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youve</th>\n",
       "      <th>yowza</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yrsday</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>zaarly</th>\n",
       "      <th>zaarlyiscoming</th>\n",
       "      <th>zagg</th>\n",
       "      <th>zaggle</th>\n",
       "      <th>zappos</th>\n",
       "      <th>zazzle</th>\n",
       "      <th>zazzlesxsw</th>\n",
       "      <th>zazzlsxsw</th>\n",
       "      <th>ze</th>\n",
       "      <th>zelda</th>\n",
       "      <th>zeldman</th>\n",
       "      <th>zero</th>\n",
       "      <th>zimride</th>\n",
       "      <th>zip</th>\n",
       "      <th>zite</th>\n",
       "      <th>zms</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zzzs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   02  03  0310  10  100  1000  ...  zms  zombies  zomg  zone  zoom  zzzs\n",
       "0   0   0     0   0    0     0  ...    0        0     0     0     0     0\n",
       "1   0   0     0   0    0     0  ...    0        0     0     0     0     0\n",
       "2   0   0     0   0    0     0  ...    0        0     0     0     0     0\n",
       "3   0   0     0   0    0     0  ...    0        0     0     0     0     0\n",
       "4   0   0     0   0    0     0  ...    0        0     0     0     0     0\n",
       "\n",
       "[5 rows x 6103 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(data_filtered_dtm.toarray(), columns=vect.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5pxd5fSHH0Nt"
   },
   "source": [
    "### 17. Find number of different words in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1065,
     "status": "ok",
     "timestamp": 1560688761028,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "p1DQ2LdNH0Nu",
    "outputId": "67fb48a9-0606-478d-f65d-146f50d4c8c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6103"
      ]
     },
     "execution_count": 220,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwtgjTBeH0Ny"
   },
   "source": [
    "#### Tip: To see all available functions for an Object use dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1560688764934,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "2n_iCcTNH0N0",
    "outputId": "cd9231cf-566e-426c-f779-d3f6bf38c2a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_char_ngrams',\n",
       " '_char_wb_ngrams',\n",
       " '_check_stop_words_consistency',\n",
       " '_check_vocabulary',\n",
       " '_count_vocab',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_limit_features',\n",
       " '_more_tags',\n",
       " '_sort_features',\n",
       " '_stop_words_id',\n",
       " '_validate_custom_analyzer',\n",
       " '_validate_params',\n",
       " '_validate_vocabulary',\n",
       " '_white_spaces',\n",
       " '_word_ngrams',\n",
       " 'analyzer',\n",
       " 'binary',\n",
       " 'build_analyzer',\n",
       " 'build_preprocessor',\n",
       " 'build_tokenizer',\n",
       " 'decode',\n",
       " 'decode_error',\n",
       " 'dtype',\n",
       " 'encoding',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'fixed_vocabulary_',\n",
       " 'get_feature_names',\n",
       " 'get_params',\n",
       " 'get_stop_words',\n",
       " 'input',\n",
       " 'inverse_transform',\n",
       " 'lowercase',\n",
       " 'max_df',\n",
       " 'max_features',\n",
       " 'min_df',\n",
       " 'ngram_range',\n",
       " 'preprocessor',\n",
       " 'set_params',\n",
       " 'stop_words',\n",
       " 'stop_words_',\n",
       " 'strip_accents',\n",
       " 'token_pattern',\n",
       " 'tokenizer',\n",
       " 'transform',\n",
       " 'vocabulary',\n",
       " 'vocabulary_']"
      ]
     },
     "execution_count": 221,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ShA6D8jKH0N5"
   },
   "source": [
    "### 18. Find out how many Positive and Negative emotions are there.\n",
    "\n",
    "Hint: Use value_counts on that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1815,
     "status": "ok",
     "timestamp": 1560688775592,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "q7LAl5pzH0N6",
    "outputId": "436d3db8-6d77-43d5-c1b0-10aba82e473d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive emotion    2672\n",
       "Negative emotion     519\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.is_there_an_emotion_directed_at_a_brand_or_product.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IUvgj0FoH0N9"
   },
   "source": [
    "### 19. Change the labels for Positive and Negative emotions as 1 and 0 respectively and store in a different column in the same dataframe named 'Label'\n",
    "\n",
    "Hint: use map on that column and give labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1146,
     "status": "ok",
     "timestamp": 1560688781725,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "YftKwFv7H0N9",
    "outputId": "f133a547-5f58-4b9d-b4f6-92e32cd71e75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_filtered['labels']=data_filtered.is_there_an_emotion_directed_at_a_brand_or_product.map({'Positive emotion':1,'Negative emotion':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1226,
     "status": "ok",
     "timestamp": 1560688786439,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "wZZ2m75VSnye",
    "outputId": "b763d2e3-a361-478b-c9ab-c3f4cb175c7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley83 I have a 3G iPhone After 3 hrs tweeti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee Know about fludapp  Awesome iPadiPhon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin Can not wait for iPad 2 also They s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>sxsw I hope this years festival isnt as crashy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff on Fri SXSW Marissa Maye...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  ... labels\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...      0\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...      1\n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...  ...      1\n",
       "3  @sxsw I hope this year's festival isn't as cra...  ...      0\n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...      1\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YErwYLCH0N_"
   },
   "source": [
    "### 20. Define the feature set (independent variable or X) to be `text` column and `labels` as target (or dependent variable)  and divide into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNkwrGgEH0OA"
   },
   "outputs": [],
   "source": [
    "X = data_filtered_dtm\n",
    "Y = data_filtered['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1560689583114,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "BmtWd0AdTqit",
    "outputId": "b6e78dbd-e198-4d78-f05b-85b07da2937d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2233, 6103)\n",
      "(958, 6103)\n",
      "(2233,)\n",
      "(958,)\n"
     ]
    }
   ],
   "source": [
    "# spliting X and Y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_dtm, X_test_dtm, y_train, y_test = train_test_split(X, Y,test_size=0.3, random_state=2)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5nlCuaaH0OD"
   },
   "source": [
    "## 21. **Predicting the sentiment:**\n",
    "\n",
    "\n",
    "### Use Naive Bayes and Logistic Regression and their accuracy scores for predicting the sentiment of the given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2AbVYssaH0OE"
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 965,
     "status": "ok",
     "timestamp": 1560689588119,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "ktXrLhmOH0Of",
    "outputId": "99e112c9-53fb-4395-b2a2-24bc8fe85fdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 237,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clv2X0kKH0Ok"
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1560689611393,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "K86LRMfdH0Ou",
    "outputId": "7d21eb30-960a-410a-f2e7-0bc69aa4920f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8549060542797495"
      ]
     },
     "execution_count": 239,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 945,
     "status": "ok",
     "timestamp": 1560689628521,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "xd96tbYNWZ3X",
    "outputId": "7c2803d0-5c99-41bf-f1be-fbe2d9ed8121"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54, 106],\n",
       "       [ 33, 765]])"
      ]
     },
     "execution_count": 240,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RF-OryYuWeLo"
   },
   "outputs": [],
   "source": [
    "# import and instantiate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3296
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 972,
     "status": "ok",
     "timestamp": 1560689685872,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "lQu16XLKWjLA",
    "outputId": "15c7736d-f961-4fe8-81d3-c6fa9a2ae2a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.98307648, 0.9668924 , 0.62424748, 0.09946203, 0.93559017,\n",
       "       0.99518585, 0.8729795 , 0.99523776, 0.95224787, 0.9681021 ,\n",
       "       0.96647662, 0.94484032, 0.9962137 , 0.87474799, 0.92885908,\n",
       "       0.96922092, 0.05910354, 0.99361293, 0.96428779, 0.96066242,\n",
       "       0.95170463, 0.65572119, 0.62268506, 0.97472789, 0.93218059,\n",
       "       0.9838908 , 0.89329853, 0.99697541, 0.95933459, 0.92790573,\n",
       "       0.96924184, 0.99842503, 0.93355818, 0.65001536, 0.73089328,\n",
       "       0.95874044, 0.99614739, 0.74749049, 0.63646453, 0.9668828 ,\n",
       "       0.97226285, 0.96361401, 0.77837282, 0.76379647, 0.81820739,\n",
       "       0.2673044 , 0.9940449 , 0.69404547, 0.68960153, 0.9776847 ,\n",
       "       0.99039984, 0.95717928, 0.99785671, 0.93141853, 0.90773494,\n",
       "       0.99870981, 0.87672225, 0.93397907, 0.99405332, 0.98119378,\n",
       "       0.98710668, 0.98535   , 0.99861685, 0.97608628, 0.79813603,\n",
       "       0.89824111, 0.94784928, 0.9960485 , 0.93449542, 0.98070753,\n",
       "       0.97232069, 0.79142647, 0.9110336 , 0.83385484, 0.99613319,\n",
       "       0.96656359, 0.99415094, 0.6637819 , 0.89315524, 0.99421508,\n",
       "       0.9968145 , 0.98768396, 0.98438015, 0.9908745 , 0.74366913,\n",
       "       0.63735853, 0.97334094, 0.98253586, 0.74595322, 0.95643453,\n",
       "       0.93036977, 0.94416953, 0.3853187 , 0.97734171, 0.77363352,\n",
       "       0.85208262, 0.90691911, 0.970906  , 0.96358956, 0.79962675,\n",
       "       0.96516437, 0.33090627, 0.98457128, 0.88210205, 0.9679126 ,\n",
       "       0.95549178, 0.46975888, 0.94909883, 0.73154921, 0.99262473,\n",
       "       0.98864017, 0.76845823, 0.95015191, 0.84288362, 0.99403423,\n",
       "       0.98171926, 0.84155687, 0.76007784, 0.955269  , 0.10531168,\n",
       "       0.92796252, 0.99130014, 0.77973091, 0.97958222, 0.98082275,\n",
       "       0.96867071, 0.1453519 , 0.98712083, 0.93736157, 0.12737945,\n",
       "       0.98697645, 0.98182026, 0.88731857, 0.9874097 , 0.99112798,\n",
       "       0.89490351, 0.94732302, 0.97755582, 0.98419971, 0.98336987,\n",
       "       0.59978012, 0.99192132, 0.65607947, 0.81632999, 0.54021405,\n",
       "       0.3970624 , 0.99060562, 0.09850805, 0.97351661, 0.9803963 ,\n",
       "       0.95621994, 0.84139298, 0.99732371, 0.98858215, 0.99170015,\n",
       "       0.8396924 , 0.97206439, 0.78916838, 0.94252115, 0.94568305,\n",
       "       0.91248042, 0.96067731, 0.87000509, 0.2377351 , 0.89171982,\n",
       "       0.9872792 , 0.94733918, 0.98204184, 0.90310565, 0.76228163,\n",
       "       0.95908253, 0.96365369, 0.7265624 , 0.91591903, 0.98293505,\n",
       "       0.992927  , 0.90750422, 0.98660047, 0.97884024, 0.99226647,\n",
       "       0.91445153, 0.99787772, 0.89747267, 0.98826141, 0.88992435,\n",
       "       0.76464836, 0.93157943, 0.96852695, 0.76269413, 0.99896751,\n",
       "       0.97474707, 0.95154539, 0.26583844, 0.68997396, 0.99928767,\n",
       "       0.85381083, 0.02313485, 0.29679738, 0.31121674, 0.17449442,\n",
       "       0.48577703, 0.81296044, 0.51087899, 0.92343757, 0.7095549 ,\n",
       "       0.1651    , 0.98779104, 0.99722266, 0.92678646, 0.95055191,\n",
       "       0.84718989, 0.93116105, 0.9865695 , 0.92659764, 0.9437397 ,\n",
       "       0.97131133, 0.98306588, 0.76567535, 0.91619578, 0.88197619,\n",
       "       0.97667959, 0.92402787, 0.98561437, 0.89547301, 0.92211019,\n",
       "       0.98670621, 0.98920031, 0.9857974 , 0.98936816, 0.99452006,\n",
       "       0.92050435, 0.98855577, 0.95854958, 0.93735535, 0.53408678,\n",
       "       0.90903748, 0.99570972, 0.94102003, 0.98133104, 0.99574516,\n",
       "       0.92728357, 0.89430883, 0.98484533, 0.99102331, 0.18981871,\n",
       "       0.97217603, 0.99564772, 0.59367081, 0.78904649, 0.97575348,\n",
       "       0.42491811, 0.96516692, 0.96221558, 0.98601471, 0.9722095 ,\n",
       "       0.99443942, 0.99489463, 0.96666522, 0.92476251, 0.97735688,\n",
       "       0.99296747, 0.97967248, 0.92590204, 0.95246101, 0.97352213,\n",
       "       0.96842228, 0.99155787, 0.95668922, 0.31675983, 0.92619364,\n",
       "       0.98913284, 0.98838892, 0.90966481, 0.96399384, 0.59692425,\n",
       "       0.9850605 , 0.13471003, 0.99684771, 0.91997393, 0.92740356,\n",
       "       0.53176   , 0.98547421, 0.80464726, 0.97668468, 0.48991977,\n",
       "       0.98586971, 0.92353806, 0.93444776, 0.47868164, 0.9788023 ,\n",
       "       0.99152851, 0.96619177, 0.99333053, 0.94729038, 0.99931397,\n",
       "       0.80250449, 0.95392611, 0.97856278, 0.93094002, 0.96213489,\n",
       "       0.94232619, 0.68624367, 0.26578335, 0.97228946, 0.98816575,\n",
       "       0.9905802 , 0.80794281, 0.91009243, 0.99051049, 0.98696802,\n",
       "       0.98691846, 0.97095662, 0.23855943, 0.9933238 , 0.95681083,\n",
       "       0.94759651, 0.97577996, 0.85601587, 0.95593345, 0.98785838,\n",
       "       0.9243161 , 0.99134914, 0.23016179, 0.89749614, 0.98089484,\n",
       "       0.999057  , 0.84683164, 0.84531817, 0.99969892, 0.99777541,\n",
       "       0.99100923, 0.93377137, 0.99016907, 0.83563301, 0.96761884,\n",
       "       0.98883103, 0.98971573, 0.97899852, 0.76994949, 0.93866996,\n",
       "       0.89732775, 0.97104395, 0.56219187, 0.93960555, 0.78264238,\n",
       "       0.99460702, 0.98690564, 0.98609911, 0.98747228, 0.99784855,\n",
       "       0.97657621, 0.96845971, 0.99696993, 0.93799107, 0.87936437,\n",
       "       0.99124854, 0.91494795, 0.88413106, 0.88210493, 0.82484942,\n",
       "       0.93090979, 0.17029627, 0.88203516, 0.97014107, 0.9158285 ,\n",
       "       0.99005924, 0.9908375 , 0.69418743, 0.92678376, 0.16575319,\n",
       "       0.40455097, 0.98965614, 0.98225846, 0.9953196 , 0.10145657,\n",
       "       0.98702087, 0.97082321, 0.49676144, 0.97459602, 0.98629599,\n",
       "       0.95647066, 0.99077315, 0.98145545, 0.76479452, 0.97607432,\n",
       "       0.99299731, 0.94738527, 0.96989192, 0.95847023, 0.9481477 ,\n",
       "       0.99598872, 0.85650351, 0.88539702, 0.99616721, 0.95172359,\n",
       "       0.9089774 , 0.3097168 , 0.95245261, 0.99157709, 0.81410264,\n",
       "       0.98974779, 0.98651977, 0.98371792, 0.83475405, 0.98806346,\n",
       "       0.84477346, 0.96660843, 0.99853344, 0.94635142, 0.87676489,\n",
       "       0.91650941, 0.94308128, 0.92755284, 0.94001928, 0.98822908,\n",
       "       0.91892363, 0.99262139, 0.97521411, 0.59141357, 0.94679586,\n",
       "       0.92474994, 0.75131049, 0.99850843, 0.98225923, 0.92809361,\n",
       "       0.63341309, 0.99546487, 0.94266707, 0.94333334, 0.06202912,\n",
       "       0.89804598, 0.98590793, 0.87566066, 0.93071058, 0.97665977,\n",
       "       0.98292883, 0.58433496, 0.98873927, 0.96948803, 0.98009232,\n",
       "       0.98613218, 0.74158472, 0.72324052, 0.99855917, 0.18437823,\n",
       "       0.99864474, 0.82773115, 0.98729255, 0.85559087, 0.96064759,\n",
       "       0.95927407, 0.87633993, 0.85598798, 0.97869805, 0.82384341,\n",
       "       0.83390646, 0.97649513, 0.95635669, 0.79773778, 0.98823428,\n",
       "       0.69024687, 0.98984515, 0.98102492, 0.19376474, 0.8401487 ,\n",
       "       0.95768157, 0.90181588, 0.99481832, 0.94569935, 0.96732121,\n",
       "       0.25173178, 0.9871458 , 0.93303387, 0.99494849, 0.53458477,\n",
       "       0.95125485, 0.9922935 , 0.52950908, 0.4907442 , 0.97832736,\n",
       "       0.95707345, 0.97612184, 0.29074147, 0.99085958, 0.97435075,\n",
       "       0.97665977, 0.97868665, 0.76777919, 0.6593475 , 0.92285017,\n",
       "       0.98181564, 0.90810615, 0.85733636, 0.98671355, 0.94597498,\n",
       "       0.80610936, 0.48574347, 0.87107082, 0.88778687, 0.99377947,\n",
       "       0.98996807, 0.96535779, 0.9746915 , 0.90864316, 0.97905626,\n",
       "       0.97308899, 0.97356922, 0.5001375 , 0.98654942, 0.99435695,\n",
       "       0.847574  , 0.97742052, 0.9537004 , 0.13085536, 0.96089085,\n",
       "       0.08883927, 0.99590199, 0.57410734, 0.89360439, 0.74338981,\n",
       "       0.87883061, 0.81131381, 0.96483687, 0.95022945, 0.98695535,\n",
       "       0.99973764, 0.95327551, 0.99435994, 0.95553003, 0.43524159,\n",
       "       0.96331151, 0.32682811, 0.9816038 , 0.17168416, 0.95934238,\n",
       "       0.98801749, 0.91452452, 0.95130447, 0.58906458, 0.87448881,\n",
       "       0.36015675, 0.97613539, 0.76758317, 0.98366888, 0.95632797,\n",
       "       0.90274922, 0.77002264, 0.64925486, 0.97199908, 0.98094673,\n",
       "       0.49213745, 0.96651497, 0.73823488, 0.993001  , 0.75141975,\n",
       "       0.96378109, 0.89412171, 0.81716689, 0.99493463, 0.23728666,\n",
       "       0.97833336, 0.93398637, 0.91502923, 0.96336625, 0.94046008,\n",
       "       0.67424823, 0.95426457, 0.97109905, 0.99848818, 0.53977783,\n",
       "       0.98650938, 0.89297823, 0.09891256, 0.26583844, 0.9735636 ,\n",
       "       0.79780237, 0.99545478, 0.85015011, 0.99437331, 0.98828378,\n",
       "       0.85300494, 0.9910667 , 0.6508659 , 0.92473049, 0.97996933,\n",
       "       0.783864  , 0.80447656, 0.29624764, 0.14179268, 0.36238772,\n",
       "       0.99317993, 0.811746  , 0.98119418, 0.96376656, 0.96584938,\n",
       "       0.94646282, 0.53423946, 0.31822037, 0.84687983, 0.97545522,\n",
       "       0.88148062, 0.9814649 , 0.49213853, 0.85916794, 0.98166916,\n",
       "       0.92140242, 0.80061537, 0.96875706, 0.88333611, 0.94698879,\n",
       "       0.61997847, 0.74809813, 0.9669595 , 0.97093513, 0.11639377,\n",
       "       0.12197604, 0.99936801, 0.99387509, 0.46742577, 0.80680544,\n",
       "       0.99754692, 0.95557258, 0.92738459, 0.91950598, 0.97966006,\n",
       "       0.98976359, 0.49798498, 0.73819482, 0.94969111, 0.97835318,\n",
       "       0.48022845, 0.96906098, 0.98940258, 0.63611323, 0.40379716,\n",
       "       0.76758245, 0.99729839, 0.82872202, 0.81614284, 0.92152514,\n",
       "       0.99457156, 0.70059587, 0.98421436, 0.99558919, 0.9276204 ,\n",
       "       0.98798307, 0.27042045, 0.97285729, 0.94676153, 0.92248082,\n",
       "       0.99475762, 0.34576302, 0.96384752, 0.8271716 , 0.97248813,\n",
       "       0.99268112, 0.94835489, 0.98567413, 0.92837139, 0.96276206,\n",
       "       0.99275268, 0.89220514, 0.99063216, 0.97460633, 0.95719523,\n",
       "       0.76387511, 0.85951055, 0.84931239, 0.97278613, 0.55652922,\n",
       "       0.74452843, 0.97273716, 0.91543462, 0.70444958, 0.95348838,\n",
       "       0.32881021, 0.9245267 , 0.98631861, 0.88101807, 0.91045725,\n",
       "       0.24903386, 0.97707198, 0.83185236, 0.78072241, 0.18551023,\n",
       "       0.83004858, 0.9639703 , 0.54155867, 0.83736755, 0.96326292,\n",
       "       0.58691779, 0.93613894, 0.97270331, 0.76686566, 0.99017494,\n",
       "       0.82674908, 0.94918415, 0.99868637, 0.92769563, 0.99717641,\n",
       "       0.28206774, 0.98009003, 0.88959132, 0.30765   , 0.88521856,\n",
       "       0.98277803, 0.86627147, 0.97018504, 0.94662861, 0.38754848,\n",
       "       0.94078369, 0.9800426 , 0.98859416, 0.98377742, 0.85363937,\n",
       "       0.92975936, 0.9725481 , 0.99950052, 0.9448272 , 0.96869782,\n",
       "       0.82507891, 0.95492679, 0.33244541, 0.96812553, 0.98989473,\n",
       "       0.87514879, 0.7555472 , 0.98359984, 0.8088132 , 0.84172173,\n",
       "       0.99098699, 0.87395289, 0.9530724 , 0.89726182, 0.54337943,\n",
       "       0.71278647, 0.73293138, 0.99237072, 0.38480203, 0.96679043,\n",
       "       0.91369206, 0.99351393, 0.42993231, 0.18281123, 0.99615909,\n",
       "       0.9670297 , 0.99694263, 0.57458585, 0.93783744, 0.96136842,\n",
       "       0.9722703 , 0.88075526, 0.98221492, 0.9646145 , 0.99440596,\n",
       "       0.89170368, 0.66711567, 0.97921941, 0.952082  , 0.98002273,\n",
       "       0.98750272, 0.92511219, 0.98530003, 0.8922863 , 0.888793  ,\n",
       "       0.97801891, 0.98899754, 0.994062  , 0.99306109, 0.5058851 ,\n",
       "       0.99280966, 0.99720208, 0.20236928, 0.92312445, 0.79808146,\n",
       "       0.98253895, 0.90846928, 0.97743732, 0.97572146, 0.93084764,\n",
       "       0.34234404, 0.96324857, 0.98550362, 0.88853198, 0.04123961,\n",
       "       0.96744114, 0.97273737, 0.97463297, 0.78349189, 0.93427096,\n",
       "       0.94784238, 0.97914614, 0.99330206, 0.73152148, 0.93238094,\n",
       "       0.99575893, 0.92696628, 0.94924626, 0.87949811, 0.71751518,\n",
       "       0.75217211, 0.96422448, 0.6023751 , 0.84820071, 0.27917286,\n",
       "       0.95697399, 0.86982212, 0.92845214, 0.96865945, 0.94879708,\n",
       "       0.77151565, 0.5568351 , 0.95315113, 0.85169757, 0.90287833,\n",
       "       0.9852219 , 0.9985619 , 0.96872136, 0.93060707, 0.86756046,\n",
       "       0.9820438 , 0.79260855, 0.98217938, 0.97235787, 0.57958848,\n",
       "       0.99594971, 0.95360127, 0.10973714, 0.64520991, 0.95525855,\n",
       "       0.05431174, 0.98875727, 0.65741934, 0.95313997, 0.97455787,\n",
       "       0.98819011, 0.99154691, 0.87358809, 0.97053648, 0.44688352,\n",
       "       0.99254196, 0.95502604, 0.87535231, 0.99164656, 0.807308  ,\n",
       "       0.96141328, 0.99845833, 0.98430306, 0.99589814, 0.97208385,\n",
       "       0.93227925, 0.81596427, 0.99254271, 0.99708466, 0.96597103,\n",
       "       0.86458405, 0.9877621 , 0.70291684, 0.96270078, 0.98185576,\n",
       "       0.5674332 , 0.93252937, 0.99622605, 0.15562522, 0.41759336,\n",
       "       0.68650493, 0.90442086, 0.60298738, 0.98055549, 0.49902703,\n",
       "       0.69262032, 0.98896231, 0.8776247 , 0.50973032, 0.86515099,\n",
       "       0.98927332, 0.98696452, 0.74701205, 0.9639795 , 0.97487165,\n",
       "       0.95414078, 0.97048361, 0.98857304, 0.06477208, 0.50801458,\n",
       "       0.92605751, 0.46395877, 0.17890891, 0.92968517, 0.38281432,\n",
       "       0.9982977 , 0.99595851, 0.14110161, 0.67804612, 0.99369528,\n",
       "       0.91390593, 0.98197354, 0.73973635, 0.98692215, 0.91932941,\n",
       "       0.73420582, 0.99421851, 0.99396768, 0.81715112, 0.98967577,\n",
       "       0.91171446, 0.91330752, 0.93879014, 0.95926951, 0.97202605,\n",
       "       0.97278478, 0.34894942, 0.99972818, 0.98771141, 0.24381687,\n",
       "       0.98286408, 0.96763926, 0.61633585, 0.98416413, 0.13636042,\n",
       "       0.82658655, 0.92479039, 0.43518466, 0.99925438, 0.69690844,\n",
       "       0.98252991, 0.15535956, 0.54242051, 0.99503597, 0.91597872,\n",
       "       0.57812443, 0.95236925, 0.99428091, 0.8671719 , 0.9435359 ,\n",
       "       0.94246733, 0.79089225, 0.92777295, 0.98438827, 0.93702974,\n",
       "       0.97973721, 0.08936935, 0.99384147, 0.71015845, 0.92472333,\n",
       "       0.4026065 , 0.92400012, 0.97253611, 0.94599176, 0.99264267,\n",
       "       0.99332412, 0.98122366, 0.98726948, 0.9980668 , 0.98680128,\n",
       "       0.80884259, 0.90183552, 0.96677928])"
      ]
     },
     "execution_count": 242,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "\n",
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "\n",
    "# calculate predicted probabilities for X_test_dtm\n",
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1261,
     "status": "ok",
     "timestamp": 1560689714887,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "ja4kLy4oWsrv",
    "outputId": "1586d782-217f-4a28-cee2-a665e03470d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872651356993737"
      ]
     },
     "execution_count": 243,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sw-0B33tH0Ox"
   },
   "source": [
    "## 22. Create a function called `tokenize_predict` which can take count vectorizer object as input and prints the accuracy for x (text) and y (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoJxx3oAW2X8"
   },
   "outputs": [],
   "source": [
    "X = data_filtered['text']\n",
    "Y = data_filtered['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dkcQGtDoXAFJ"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okCTOs1TH0Oy"
   },
   "outputs": [],
   "source": [
    "def tokenize_test(vect):\n",
    "    x_train_dtm = vect.fit_transform(x_train)\n",
    "    print('Features: ', x_train_dtm.shape[1])\n",
    "    x_test_dtm = vect.transform(x_test)\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(x_train_dtm, y_train)\n",
    "    y_pred_class = nb.predict(x_test_dtm)\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1000,
     "status": "ok",
     "timestamp": 1560689835307,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "TIYgjebGXJ0L",
    "outputId": "284bc34e-c1d9-4537-d132-6d8b22e21c55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  5066\n",
      "Accuracy:  0.8653444676409185\n"
     ]
    }
   ],
   "source": [
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxZ8jfPEH0O0"
   },
   "source": [
    "### Create a count vectorizer function which includes n_grams = 1,2  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 960,
     "status": "ok",
     "timestamp": 1560689909927,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "kdCyAN_IH0O0",
    "outputId": "d17e4e08-8d01-4a4c-e285-2a5b9df742d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  23899\n",
      "Accuracy:  0.8757828810020877\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "axepytmgH0O4"
   },
   "source": [
    "### Create a count vectorizer function with stopwords = 'english'  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 897,
     "status": "ok",
     "timestamp": 1560690001927,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "HToGkq7vH0O4",
    "outputId": "2240e47a-6795-48fb-9004-2fdbaf887ccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  4828\n",
      "Accuracy:  0.8653444676409185\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english')\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iOIlJRxoH0O7"
   },
   "source": [
    "### Create a count vectorizer function with stopwords = 'english' and max_features =300  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1001,
     "status": "ok",
     "timestamp": 1560690024178,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "6fUhff-oH0O8",
    "outputId": "b567a08a-bff5-454d-c5b4-9c84da1bc190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  300\n",
      "Accuracy:  0.8225469728601252\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english',max_features=300)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2KZNWVkH0PA"
   },
   "source": [
    "### Create a count vectorizer function with n_grams = 1,2  and max_features = 15000  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 941,
     "status": "ok",
     "timestamp": 1560690068108,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "3v9XD082H0PB",
    "outputId": "bca3eee1-88c2-4cc6-d6ec-c098e601922c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  15000\n",
      "Accuracy:  0.8716075156576201\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2),max_features=15000)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "We3JK_SRH0PO"
   },
   "source": [
    "### Create a count vectorizer function with n_grams = 1,2  and include terms that appear at least 2 times (min_df = 2)  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 935,
     "status": "ok",
     "timestamp": 1560690090965,
     "user": {
      "displayName": "Diksha Singh",
      "photoUrl": "https://lh4.googleusercontent.com/-x3-ufhtCiQU/AAAAAAAAAAI/AAAAAAAAAFY/F5pCqY8v8Fg/s64/photo.jpg",
      "userId": "07661533439928129655"
     },
     "user_tz": -330
    },
    "id": "fUHrfDCyH0PP",
    "outputId": "ddda4151-27a8-4e12-cfaa-cc8a7a9f70b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  7325\n",
      "Accuracy:  0.8768267223382046\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2),min_df=2)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3H4k_lVZH0PS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R8_Internal_Lab_Questions_Transfer_Learning_MNIST_Tweet_Sentiment_Analysis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
